<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Kenshi Abe">
    <meta name="description" content="https://bakanaouji.github.io/">
    <meta name="keywords" content="portfolio,researcher,personal">

    <meta property="og:site_name" content="Kenshi Abe">
    <meta property="og:title" content="
   - Kenshi Abe
">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://bakanaouji.github.io/works/">
    <meta property="og:image" content="https://bakanaouji.github.io/&lt;no value&gt;">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="https://bakanaouji.github.io/works/">
    <meta name="twitter:image" content="https://bakanaouji.github.io/&lt;no value&gt;">

    <base href="https://bakanaouji.github.io/works/">
    <title>
   - Kenshi Abe
</title>

    <link rel="canonical" href="https://bakanaouji.github.io/works/">
    
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
    
    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="/css/normalize.min.css">
    <link rel="stylesheet" href="/css/style.min.css">

    

    
      <link rel="stylesheet" href="https://bakanaouji.github.io/custom.css">
    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    
      <link rel="alternate" href="https://bakanaouji.github.io/index.xml" type="application/rss+xml" title="Kenshi Abe">
      <link href="https://bakanaouji.github.io/index.xml" rel="feed" type="application/rss+xml" title="Kenshi Abe" />
    

    <meta name="generator" content="Hugo 0.59.1" />
  </head>

  <body class="">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">Kenshi Abe</a>
    <input type="checkbox" id="menu-control"/>
    <label class="menu-mobile  float-right " for="menu-control">
      <span class="btn-mobile  float-right ">&#9776;</span>
      <ul class="navigation-list">
        
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="https://bakanaouji.github.io/about">About</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="https://bakanaouji.github.io/works">Works</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="https://qiita.com/bakanaouji">Blog</a>
            </li>
          
        
        
      </ul>
    </label>
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1></h1>
    </header>

    

<h1 id="research">Research</h1>

<h5 id="international-conference">International Conference</h5>

<ul>
<li>Yuki Shimano, Kenshi Abe, Atsushi Iwasaki and Kazunori Ohkawara: &ldquo;Computing Strategies of American Football via Counterfactual Regret Minimization&rdquo;, <a href="http://aaai-rlg.mlanctot.info/sched.html">AAAI 2022 Workshop on Reinforcement Learning in Games (Oral Presentation)</a>, 2022.</li>
<li>Kenshi Abe, Yusuke Kaneko: &ldquo;Off-Policy Exploitability-Evaluation in Two-Player Zero-Sum Markov Games&rdquo;, <a href="https://arxiv.org/abs/2007.02141">AAMAS 2021 (Full Paper)</a>, 2021.</li>
<li>Gota Morishita<sup>*</sup>, Kenshi Abe<sup>*</sup>, Kazuhisa Ogawa, Yusuke Kaneko: &ldquo;Online Learning for Bidding Agent in First Price Auction&rdquo;, <a href="http://aaai-rlg.mlanctot.info/papers/AAAI20-RLG_paper_9.pdf">AAAI 2020 Workshop on Reinforcement Learning in Games</a>, 2020. (<sup>*</sup>equal contribution)</li>
</ul>

<h5 id="preprints">Preprints</h5>

<ul>
<li>Kaito Ariu, Kenshi Abe, Alexandre Proutière: “Thresholded LASSO Bandit”, [<a href="https://arxiv.org/abs/2010.11994">Arxiv</a>].</li>
<li>Masahiro Kato, Kenshi Abe, Kaito Ariu, Shota Yasui: “A Practical Guide of Off-Policy Evaluation for Bandit Problems”, [<a href="https://arxiv.org/abs/2010.12470">Arxiv</a>].</li>
<li>Masahiro Nomura, Kenshi Abe: &ldquo;A Simple Heuristic for Bayesian Optimization with A Low Budget&rdquo;. [<a href="https://arxiv.org/abs/1911.07790">Arxiv</a>].</li>
</ul>

<h5 id="internal-conference">Internal Conference</h5>

<ul>
<li>坂本充生, 阿部拳之, 岩崎敦: &ldquo;見間違えのある繰り返し囚人のジレンマにおける方策勾配法に関する研究&rdquo;, <a href="https://www.ipsj.or.jp/award/9faeag0000004eyo-att/CF-002.pdf">第20回情報科学技術フォーラム</a>, 2021.</li>
<li>阿部拳之, 金子雄祐: &ldquo;二人零和マルコフゲームにおけるオフ方策評価のためのQ学習&rdquo;, <a href="https://www.logos.ic.i.u-tokyo.ac.jp/~tsuruoka/sig-gi/gpw/2020/index.html">第25回ゲームプログラミングワークショップ</a>, 2020.</li>
<li>阿部拳之: &ldquo;広告配信オークションにおける入札戦略&rdquo;, <a href="https://www.ipsj.or.jp/event/fit/fit2020/splist-AITECHTALK.html">第19回情報科学技術フォーラム</a>, 2020.</li>
<li>阿部拳之: &ldquo;多人数不完全情報ゲームにおけるAI開発&rdquo;, <a href="https://www.jeameetings.org/2020s/index.html">日本経済学会 2020年度春季大会</a>, 2020.</li>
<li>阿部拳之: &ldquo;花札におけるナッシュ均衡戦略の計算&rdquo;, <a href="http://ibisml.org/ibis2019/">第22回情報論的学習理論ワークショップ (IBIS2019)</a>, 2019.</li>
<li>野村将寛, 阿部拳之: &ldquo;<a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2019/0/JSAI2019_4Rin102/_article/-char/ja">Black-box最適化に対するBudgetを考慮した探索空間の初期化</a>&rdquo;, <a href="https://www.ai-gakkai.or.jp/jsai2019/">第33回人工知能学会全国大会</a>, 2019.</li>
<li>阿部拳之, 野村将寛: &ldquo;非定常多腕バンディットアルゴリズムを用いたハイパーパラメータ最適化フレームワークの提案&rdquo;, <a href="http://ibisml.org/ibis2018/">第21回情報論的学習理論ワークショップ (IBIS2018)</a>, 2018.</li>
<li>阿部拳之, 小野功: &ldquo;活用と探索の釣り合いを考慮した事例ベース政策最適化&rdquo;, <a href="http://www.jpnsec.org/symposium201701.html">第12回進化計算学会研究会</a>, 2017. (ベストポスター発表賞)</li>
<li>阿部拳之, 小野功: &ldquo;多峰性景観下での自然進化戦略による事例ベース政策最適化&rdquo;, <a href="https://www.sice.or.jp/org/SSI2016/">計測自動制御学会システム・情報部門学術講演会2016 (SSI2016)</a>, 2016.</li>
<li>阿部拳之, 小野功: &ldquo;自然進化戦略を用いた事例ベース政策最適化&rdquo;, <a href="https://www.sice.or.jp/system/system_ken54.html">第54回システム工学部会研究会</a>, 2016.</li>
</ul>

<h1 id="presentations">Presentations</h1>

<ul>
<li><a href="https://www.slideshare.net/KenshiAbe/ai-165308197">多人数不完全情報ゲームにおけるAI ~ポーカーと麻雀を例として~</a></li>
<li>論文勉強会

<ul>
<li><a href="https://www.slideshare.net/KenshiAbe/deep-counterfactual-regret-minimization">Deep Counterfactual Regret Minimization</a></li>
<li><a href="https://www.slideshare.net/KenshiAbe/competitive-multiagent-inverse-reinforcement-learning-with-suboptimal-demonstrations-153126367">Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations</a></li>
<li><a href="https://www.slideshare.net/KenshiAbe/deep-qlearning-from-demonstrations">Deep Q-learning from Demonstrations</a></li>
<li><a href="https://www.slideshare.net/KenshiAbe/multiagent-reinforcement-learning-in-sequential-social-dilemmas-144749583">Multi-agent Reinforcement Learning in Sequential Social Dilemmas</a></li>
<li><a href="https://www.slideshare.net/KenshiAbe/evolved-policy-gradients">Evolved policy gradients</a></li>
</ul></li>
</ul>

<h1 id="blog-posts">Blog Posts</h1>

<ul>
<li><a href="https://qiita.com/bakanaouji/items/f70d7948931c96d94ef8">【ゲーム理論】展開型ゲームのナッシュ均衡を計算しよう：Counterfactual Regret Minimizationの解説</a></li>
<li><a href="https://qiita.com/bakanaouji/items/fefa93cc53cafbdd985d">【Unity ML-Agents】 Self-Play Reinforcement Learningで対戦ゲームのAIを作ってみた</a></li>
<li><a href="https://qiita.com/bakanaouji/items/d20c8903a1327e660de5">Q-Learningがどの程度Off-Policyなのかを調べてみた</a></li>
<li><a href="https://cyberagent.ai/blog/research/2522/">ミニ花札のAIを作ってみよう</a></li>
<li><a href="https://qiita.com/bakanaouji/items/aa076cef1e04f77f48ce">遺伝的アルゴリズムでコードフォーマッタのスタイルを最適化する</a></li>
<li><a href="https://qiita.com/bakanaouji/items/75444b4d97ede83c7c48">max k-armed banditとは？</a></li>
<li><a href="https://cyberagent.ai/blog/research/1036">Successive Halvingの性能解析</a></li>
</ul>

  </article>
</section>


      </div>
      
        <footer class="footer">
  <section class="container">
    
      <div class="sns-shares sp-sns-shares">
        
        
        
        
        
      </div>
    
    
     © 2019    ·  Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/naro143/hugo-coder-portfolio">CoderPortfolio</a>. 

  </section>
</footer>
<div class="fixed-bar">
  <section class="container">
    
      <p id="privateTriggerText">Do you want to get in touch with me? →<a id="privateTrigger">Click!</a></p>
    
    
      <div class="sns-shares pc-sns-shares">
        
        
        
        
        
      </div>
    
  </section>
</div>

      
    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-150920247-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  <script src="/js/app.js"></script>
  
  <script>
  (function($) {
    $(function() {
      $('#privateTrigger').on('click', function() {
        $('.private').slideToggle();
        $('#privateTriggerText').text("Thank You! Please share it if you like it→");
      });
    });
   })(jQuery);
  </script>
  
  </body>
</html>
