+++ 
draft = false
date = 2019-10-24T06:01:09+09:00
title = ""
slug = "" 
tags = []
categories = []
thumbnail = "<no value>"
description = ""
+++

# Research
##### International Conference
1. Kaito Ariu, Kenshi Abe, Alexandre Proutière.<br>
**Thresholded LASSO Bandit**<br>
ICML 2022. [[paper](https://arxiv.org/abs/2010.11994)]
1. Kenshi Abe, Junpei Komiyama, Atsushi Iwasaki.<br>
**Anytime Capacity Expansion in Medical Residency Match by Monte Carlo Tree Search**<br>
IJCAI 2022. [[paper](https://arxiv.org/abs/2202.06570)]
1. Yuki Shimano, Kenshi Abe, Atsushi Iwasaki, Kazunori Ohkawara.<br>
**Computing Strategies of American Football via Counterfactual Regret Minimization**<br>
AAAI 2022 Workshop on Reinforcement Learning in Games (Oral Presentation). [[paper](http://aaai-rlg.mlanctot.info/papers/AAAI22-RLG_paper_23.pdf)]
1. Kenshi Abe, Yusuke Kaneko.<br>
**Off-Policy Exploitability-Evaluation in Two-Player Zero-Sum Markov Games**<br>
AAMAS 2021 (Full Paper). [[paper](https://arxiv.org/abs/2007.02141)]
1. Gota Morishita<sup>\*</sup>, Kenshi Abe<sup>\*</sup>, Kazuhisa Ogawa, Yusuke Kaneko (<sup>\*</sup>equal contribution).<br>
**Online Learning for Bidding Agent in First Price Auction**<br>
AAAI 2020 Workshop on Reinforcement Learning in Games. [[paper](http://aaai-rlg.mlanctot.info/papers/AAAI20-RLG_paper_9.pdf)].

##### Preprints
1. Masahiro Kato, Kenshi Abe, Kaito Ariu, Shota Yasui.<br>
**A Practical Guide of Off-Policy Evaluation for Bandit Problems**<br>
[[Arxiv](https://arxiv.org/abs/2010.12470)].
1. Masahiro Nomura, Kenshi Abe.<br>
**A Simple Heuristic for Bayesian Optimization with A Low Budget**.<br>
[[Arxiv](https://arxiv.org/abs/1911.07790)].

##### Internal Conference
1. 坂本充生, 阿部拳之, 岩崎敦.<br>
見間違えのある繰り返しゲームのためのActor-Critic型強化学習.<br>
[日本オペレーションズ・リサーチ学会 2021年 秋季研究発表会](https://ibisml.org/ibis2021/). [[paper](https://orsj.org/nc2021f/wp-content/uploads/sites/2/2021/08/2021f-2-C-11.pdf)]
1. 坂本充生, 阿部拳之, 岩崎敦.<br>
見間違えのある繰り返しゲームのためのActor-Critic型強化学習.<br>
[第24回情報論的学習理論ワークショップ (IBIS2021)](https://ibisml.org/ibis2021/).
1. 島野雄貴, 阿部拳之, 岩崎敦, 大河原一憲.<br>
反実仮想後悔最小化によるアメリカンフットボールにおけるオフェンス戦略の均衡推定.<br>
[第20回情報科学技術フォーラム (FIT 2021)](https://www.ipsj.or.jp/event/fit/fit2021/FIT2021_program/data/html/program/f.html).
1. 坂本充生, 阿部拳之, 岩崎敦.<br>
見間違えのある繰り返し囚人のジレンマにおける方策勾配法に関する研究.<br>
[第20回情報科学技術フォーラム (FIT 2021)](https://www.ipsj.or.jp/event/fit/fit2021/FIT2021_program/data/html/program/f.html) (FIT船井ベストペーパー賞). [[paper](https://www.ipsj.or.jp/award/9faeag0000004eyo-att/CF-002.pdf)]
1. 阿部拳之, 金子雄祐.<br>
二人零和マルコフゲームにおけるオフ方策評価のためのQ学習.<br>
[第25回ゲームプログラミングワークショップ (GPW 2020)](https://www.logos.ic.i.u-tokyo.ac.jp/~tsuruoka/sig-gi/gpw/2020/index.html). [[paper]](https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=207671&item_no=1&page_id=13&block_id=8)
1. 阿部拳之.<br>
広告配信オークションにおける入札戦略.<br>
[第19回情報科学技術フォーラム (FIT 2020)](https://www.ipsj.or.jp/event/fit/fit2020/splist-AITECHTALK.html).
1. 阿部拳之.<br>
多人数不完全情報ゲームにおけるAI開発.<br>
[日本経済学会 2020年度春季大会](https://www.jeameetings.org/2020s/index.html).
1. 阿部拳之.<br>
花札におけるナッシュ均衡戦略の計算.<br>
[第22回情報論的学習理論ワークショップ (IBIS2019)](http://ibisml.org/ibis2019/).
1. 野村将寛, 阿部拳之.<br>
Black-box最適化に対するBudgetを考慮した探索空間の初期化.<br>
[第33回人工知能学会全国大会 (JSAI 2019)](https://www.ai-gakkai.or.jp/jsai2019/). [[paper](https://www.jstage.jst.go.jp/article/pjsai/JSAI2019/0/JSAI2019_4Rin102/_article/-char/ja)]
1. 阿部拳之, 野村将寛.<br>
非定常多腕バンディットアルゴリズムを用いたハイパーパラメータ最適化フレームワークの提案.<br>
[第21回情報論的学習理論ワークショップ (IBIS2018)](http://ibisml.org/ibis2018/).
1. 阿部拳之, 小野功.<br>
活用と探索の釣り合いを考慮した事例ベース政策最適化.<br>
[第12回進化計算学会研究会 (2017年)](http://www.jpnsec.org/symposium201701.html). (ベストポスター発表賞)
1. 阿部拳之, 小野功.<br>
多峰性景観下での自然進化戦略による事例ベース政策最適化.<br>
[計測自動制御学会システム・情報部門学術講演会 (SSI2016)](https://www.sice.or.jp/org/SSI2016/).
1. 阿部拳之, 小野功.<br>
自然進化戦略を用いた事例ベース政策最適化.<br>
[第54回システム工学部会研究会 (2016年)](https://www.sice.or.jp/system/system_ken54.html).

# Presentations
* [二人零和マルコフゲームにおけるオフ方策評価](https://www.slideshare.net/KenshiAbe/ss-248654457)
* [多人数不完全情報ゲームにおけるAI ~ポーカーと麻雀を例として~](https://www.slideshare.net/KenshiAbe/ai-165308197)
* 論文勉強会
    * [Deep Counterfactual Regret Minimization](https://www.slideshare.net/KenshiAbe/deep-counterfactual-regret-minimization)
    * [Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations](https://www.slideshare.net/KenshiAbe/competitive-multiagent-inverse-reinforcement-learning-with-suboptimal-demonstrations-153126367)
    * [Deep Q-learning from Demonstrations](https://www.slideshare.net/KenshiAbe/deep-qlearning-from-demonstrations)
    * [Multi-agent Reinforcement Learning in Sequential Social Dilemmas](https://www.slideshare.net/KenshiAbe/multiagent-reinforcement-learning-in-sequential-social-dilemmas-144749583)
    * [Evolved policy gradients](https://www.slideshare.net/KenshiAbe/evolved-policy-gradients)

# Blog Posts
* [【ゲーム理論】展開型ゲームのナッシュ均衡を計算しよう：Counterfactual Regret Minimizationの解説](https://qiita.com/bakanaouji/items/f70d7948931c96d94ef8)
* [【Unity ML-Agents】 Self-Play Reinforcement Learningで対戦ゲームのAIを作ってみた](https://qiita.com/bakanaouji/items/fefa93cc53cafbdd985d)
* [Q-Learningがどの程度Off-Policyなのかを調べてみた](https://qiita.com/bakanaouji/items/d20c8903a1327e660de5)
* [ミニ花札のAIを作ってみよう](https://cyberagent.ai/blog/research/2522/)
* [遺伝的アルゴリズムでコードフォーマッタのスタイルを最適化する](https://qiita.com/bakanaouji/items/aa076cef1e04f77f48ce)
* [max k-armed banditとは？](https://qiita.com/bakanaouji/items/75444b4d97ede83c7c48)
* [Successive Halvingの性能解析](https://cyberagent.ai/blog/research/1036)
